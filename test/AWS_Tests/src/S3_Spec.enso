from Standard.Base import all
from Standard.Base.Runtime import assert
import Standard.Base.Errors.Common.Forbidden_Operation
import Standard.Base.Errors.Illegal_Argument.Illegal_Argument
import Standard.Base.Errors.No_Such_Key.No_Such_Key
import Standard.Base.Runtime.Context
import Standard.Base.Runtime.Ref.Ref

from Standard.AWS import S3, S3_File, AWS_Credential
from Standard.AWS.Errors import AWS_SDK_Error, More_Records_Available, S3_Error, S3_Bucket_Not_Found

from Standard.Test import Test, Test_Suite
import Standard.Test.Extensions

import enso_dev.Base_Tests.Network.Enso_Cloud.Cloud_Tests_Setup.Cloud_Tests_Setup
from enso_dev.Base_Tests.Network.Enso_Cloud.Cloud_Tests_Setup import with_retries

spec =
    bucket_name = "enso-data-samples"
    writable_bucket_name = "enso-ci-s3-test-stage"
    not_a_bucket_name = "not_a_bucket_enso"
    object_name = "Bus_Stop_Benches.geojson"
    folder_name = "examples/"
    sub_folder_name = "examples/folder 1/"
    api_pending = if Environment.get "AWS_ACCESS_KEY_ID" . is_nothing then "No Access Key found." else Nothing
    cloud_setup = Cloud_Tests_Setup.prepare

    Test.group "S3.parse_uri" <|
        Test.specify "parse bucket only uris" <|
            S3.parse_uri "s3://" . should_equal (Pair.new "" "")
            S3.parse_uri "s3://asda" . should_equal (Pair.new "asda" "")
            S3.parse_uri "s3://banana/" . should_equal (Pair.new "banana" "")

        Test.specify "parse full paths uris" <|
            S3.parse_uri "s3://banana/apple" . should_equal (Pair.new "banana" "apple")
            S3.parse_uri "s3://banana/apple/orange" . should_equal (Pair.new "banana" "apple/orange")

        Test.specify "reject invalid urils" <|
            S3.parse_uri "asda" . should_equal Nothing
            S3.parse_uri "s3:///" . should_equal Nothing
            S3.parse_uri "s3:///apple/orange" . should_equal Nothing

    buckets = Ref.new []
    Test.group "S3.list_buckets" pending=api_pending <|
        Test.specify "should be able to list buckets" <|
            bucket_list = S3.list_buckets . should_succeed
            buckets.put bucket_list
            if bucket_name != Nothing then bucket_list . should_contain bucket_name

        Test.specify "should handle auth issues" <|
            S3.list_buckets (AWS_Credential.Profile "NoSuchProfile") . should_fail_with AWS_SDK_Error

        Test.specify "should not work with invalid credentials" <|
            S3.list_buckets (AWS_Credential.Key "foo" "bar") . should_fail_with S3_Error

        Test.specify "should allow to use Enso secrets within credentials" pending=cloud_setup.pending <| cloud_setup.with_prepared_environment <|
            secret_key_id = Enso_Secret.create "my_test_secret-AWS-keyid" (Environment.get "AWS_ACCESS_KEY_ID")
            secret_key_id.should_succeed
            Panic.with_finalizer secret_key_id.delete <|
                secret_key_value = Enso_Secret.create "my_test_secret-AWS-secretkey" (Environment.get "AWS_SECRET_ACCESS_KEY")
                secret_key_value.should_succeed
                Panic.with_finalizer secret_key_value.delete <| with_retries <|
                    r2 = S3.list_buckets (AWS_Credential.Key secret_key_id secret_key_value)
                    r2.should_succeed
                    r2.should_be_a Vector

    ## Rest of tests need a functional S3 connection
    pending = if bucket_name.is_nothing then "No S3 bucket set." else if buckets.get.is_error then "S3 Access Failed." else if buckets.get.contains bucket_name then Nothing else "S3 Bucket Not Found."

    Test.group "S3.head (bucket)" pending=pending <|
        Test.specify "should be able to head a bucket" <|
            S3.head bucket_name . should_equal Map.empty
            S3.head not_a_bucket_name . should_fail_with S3_Bucket_Not_Found

    Test.group "S3.read_bucket" pending=pending <|
        Test.specify "should be able to read bucket" <|
            objects_and_folders = S3.read_bucket bucket_name
            folders = objects_and_folders.first
            folders . should_contain folder_name

            objects = objects_and_folders.second
            objects . should_contain object_name

        Test.specify "should be able to read sub folder" <|
            objects_and_folders = S3.read_bucket bucket_name folder_name
            folders = objects_and_folders.first
            folders . should_contain sub_folder_name

        Test.specify "should attach a warning if not a complete list" <|
            objects = S3.read_bucket bucket_name max_count=1

            warnings = Warning.get_all objects
            warnings.length . should_equal 1

            warning = warnings.first
            warning.value.should_be_a More_Records_Available

        Test.specify "should handle missing bucket gracefully" <|
            S3.read_bucket not_a_bucket_name . should_fail_with S3_Bucket_Not_Found

        Test.specify "should handle auth issues" <|
            S3.read_bucket bucket_name credentials=(AWS_Credential.Profile "NoSuchProfile") . should_fail_with AWS_SDK_Error

    list = Ref.new []
    Test.group "S3.list_objects" pending=pending <|
        Test.specify "should be able to list objects" <|
            objects = S3.list_objects bucket_name
            objects . should_contain object_name
            list.put objects

        Test.specify "should attach a warning if not a complete list" <|
            objects = S3.list_objects bucket_name max_count=1

            warnings = Warning.get_all objects
            warnings.length . should_equal 1

            warning = warnings.first
            warning.value.should_be_a More_Records_Available

        Test.specify "should handle missing bucket gracefully" <|
            S3.list_objects not_a_bucket_name . should_fail_with S3_Bucket_Not_Found

        Test.specify "should handle auth issues" <|
            S3.list_objects bucket_name credentials=(AWS_Credential.Profile "NoSuchProfile") . should_fail_with AWS_SDK_Error

    ## These tests need a valid object, so check we found it within the bucket.
    pending_object = if pending.is_nothing.not then pending else
        if list.get.contains object_name then Nothing else
            "Unable to find test object in bucket."

    Test.group "S3.head (object)" pending=pending_object <|
        Test.specify "should be able to head an object" <|
            S3.head bucket_name object_name . should_succeed
            S3.head not_a_bucket_name object_name . should_fail_with No_Such_Key
            S3.head bucket_name "not_an_object" . should_fail_with No_Such_Key

        Test.specify "should handle auth issues" <|
            S3.list_objects bucket_name object_name credentials=(AWS_Credential.Profile "NoSuchProfile") . should_fail_with AWS_SDK_Error

    Test.group "S3.get_object" pending=pending_object <|
        Test.specify "should be able to get an object" <|
            response = S3.get_object bucket_name object_name
            response.should_succeed
            response.decode_as_json.should_succeed

            S3.get_object not_a_bucket_name object_name . should_fail_with S3_Bucket_Not_Found
            S3.get_object bucket_name "not_an_object" . should_fail_with No_Such_Key

        Test.specify "should handle auth issues" <|
            S3.get_object bucket_name object_name credentials=(AWS_Credential.Profile "NoSuchProfile") . should_fail_with AWS_SDK_Error

    Test.group "S3_File reading" pending=pending <|
        root = S3_File.new "s3://"+bucket_name+"/"
        hello_txt = S3_File.new "s3://"+bucket_name+"/examples/folder 2/hello.txt"
        Test.specify "should be able to list the bucket's root directory" <|
            r = root.list
            r.should_succeed

            r.map .name . should_contain object_name

        Test.specify "should be able to read a file" <|
            f = root / "locations.json"
            r = f.read
            r.should_be_a Vector
            r.at 0 . get "name" . should_equal "Green St Green"

        Test.specify "should be able to read a file as bytes or stream" <|
            bytes = hello_txt.read_bytes
            bytes.should_equal "Hello WORLD!".utf_8

            bytes2 = hello_txt.with_input_stream [File_Access.Read] stream->
                stream.read_all_bytes

            bytes2.should_equal bytes

        Test.specify "should support path traversal" <|
            hello_txt.parent.parent.parent . should_equal root
            hello_txt.parent . should_equal (root / "examples" / "folder 2")

            hello_txt.is_descendant_of root . should_be_true
            root.is_descendant_of hello_txt . should_be_false

        Test.specify "should be able to read file metadata" <|
            root.exists . should_be_true
            hello_txt.exists . should_be_true
            root.is_directory . should_be_true
            hello_txt.is_directory . should_be_false
            root.is_regular_file . should_be_false
            hello_txt.is_regular_file . should_be_true

            root.extension . should_fail_with S3_Error
            hello_txt.extension . should_equal ".txt"

            root.size.should_fail_with S3_Error

            hello_txt.size.should_equal 12
            hello_txt.creation_time . should_be_a Date_Time
            hello_txt.last_modified_time . should_be_a Date_Time

    Test.group "S3_File writing" pending=pending <|
        writable_root = S3_File.new "s3://"+writable_bucket_name+"/"
        my_writable_dir = writable_root / "test-run-"+(Date_Time.now.format "yyyy-MM-dd_HHmmss.fV")+"/"
        assert my_writable_dir.is_directory
        delete_on_panic file ~action =
            handler caught_panic =
                file.delete
                Panic.throw caught_panic
            Panic.catch Any action handler
        delete_afterwards file ~action =
            Panic.with_finalizer file.delete action
        Test.specify "should be able to write and delete a new file" pending="TODO" <|
            new_file = my_writable_dir / "new_file1.txt"
            "Hello".write new_file . should_succeed

            delete_on_panic new_file <|
                new_file.exists . should_be_true
                new_file.read . should_equal "Hello"
                new_file.size.should_equal 5

                my_writable_dir.list . should_contain new_file

            new_file.delete . should_succeed

            new_file.exists . should_be_false
            my_writable_dir.list . should_not_contain new_file

        Test.specify "should support .bak logic" pending="TODO" <|
            Error.throw "TODO"

        Test.specify "should be able to overwrite a file" pending="TODO" <|
            new_file = my_writable_dir / "new_file-overwrite.txt"
            "Hello".write new_file . should_succeed
            delete_afterwards new_file <|
                new_file.read . should_equal "Hello"

                "World".write new_file . should_succeed
                new_file.read . should_equal "World"

        Test.specify "should not be able to append to a file" pending="TODO" <|
            new_file = my_writable_dir / "new_file-append.txt"
            "Hello".write new_file . should_succeed
            delete_afterwards new_file <|
                r = "World".write new_file on_existing_file=Existing_File_Behavior.Append
                # TODO what exception?
                r.should_fail_with Any
                r.catch.to_display_text . should_contain "You can download the file, append locally and then upload it again."

        Test.specify "should be able to write a raw stream" <|
            new_file = my_writable_dir / "new_file-stream.txt"
            r = new_file.with_output_stream [File_Access.Write] stream->
                stream.write_bytes [1, 2, 3]
            r.should_succeed

            delete_afterwards new_file <|
                new_file.read_bytes.should_equal [1, 2, 3]

        Test.specify "is not able to open the stream in append mode" <|
            new_file = my_writable_dir / "new_file-stream-append.txt"
            r = new_file.with_output_stream [File_Access.Write, File_Access.Append] _->Nothing
            r.should_fail_with Illegal_Argument

        Test.specify "will respect the File_Access.Create_New option and fail if the file already exists" <|
            new_file = my_writable_dir / "new_file-stream-create-new.txt"
            r = new_file.with_output_stream [File_Access.Write] stream->
                stream.write_bytes [1, 2, 3]
            r.should_succeed

            delete_afterwards new_file <|
                r2 = new_file.with_output_stream [File_Access.Write, File_Access.Create_New] _->Nothing
                r2.should_fail_with S3_Error
                r2.catch.to_display_text . should_contain "already exists"

        Test.specify "should be able to write a vector of bytes" pending="TODO" <|
            new_file = my_writable_dir / "new_file-bytes.txt"
            new_file.write_bytes [4, 5, 6] . should_succeed
            delete_afterwards new_file <|
                new_file.read_bytes.should_equal [4, 5, 6]

        Test.specify "should fail open an output stream if Output context is not enabled" <|
            Context.Output.with_disabled <|
                new_file = my_writable_dir / "new_file-ctx.txt"
                new_file.with_output_stream [File_Access.Write] _->Nothing . should_fail_with Forbidden_Operation

        Test.specify "should fail to write if Output context is not enabled" pending="TODO" <|
            Context.Output.with_disabled <|
                new_file = my_writable_dir / "new_file-ctx.txt"
                "Hello".write new_file . should_fail_with Forbidden_Operation
                new_file.exists . should_be_false

main = Test_Suite.run_main spec
